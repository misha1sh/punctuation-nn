{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VARIANTS_CNT': 3, 'TARGET_CLASSES_COUNT': 3, 'INPUT_WORDS_CNT': 32, 'PUNCTUATION_TARGET': {'$empty': 0, ',': 1, '.': 2, '!': 2, '?': 2}, 'USE_NAVEC': True, 'CUT_NAVEC_TAGS_SET': set(), 'RETAIN_LEFT_PUNCT': True, 'type': 'lenta', 'NON_PUNCT_PROB': 0.5, 'INFECTED_TEXT_PROB': 0.5, 'INFECT_TYPE_PROBS': {'REPLACE_UNDEF': 0.1, 'INCORRECT_PUNCT_RANDOM_PLACE': 0.1, 'INCORRECT_PUNCT_CENTER': 0.2, 'CORRECT_PUNCT_CENTER': 0.3, 'CORRECT_PUNCT_RIGHT': 0.3}, 'feature_tags_dict': {'1per': 0, '2per': 1, '3per': 2, 'ADJF': 3, 'ADJS': 4, 'ADVB': 5, 'Abbr': 6, 'Apro': 7, 'CAPITALIZED': 8, 'COMP': 9, 'CONJ': 10, 'Fixd': 11, 'GRND': 12, 'INFN': 13, 'INTJ': 14, 'LATIN': 15, 'NOUN': 16, 'NPRO': 17, 'NUMB': 18, 'NUMR': 19, 'PRCL': 20, 'PRED': 21, 'PREP': 22, 'PRTF': 23, 'PRTS': 24, 'PUNCT_COMMA': 25, 'PUNCT_DASH': 26, 'PUNCT_DOT': 27, 'PUNCT_LEFT_PARENTHESIS': 28, 'PUNCT_QUOTE': 29, 'PUNCT_RIGHT_PARENTHESIS': 30, 'Prnt': 31, 'UNKN': 32, 'VERB': 33, 'ablt': 34, 'acc2': 35, 'accs': 36, 'actv': 37, 'datv': 38, 'femn': 39, 'futr': 40, 'gen1': 41, 'gen2': 42, 'gent': 43, 'impf': 44, 'impr': 45, 'indc': 46, 'intr': 47, 'loc1': 48, 'loc2': 49, 'loct': 50, 'masc': 51, 'neut': 52, 'nomn': 53, 'past': 54, 'perf': 55, 'plur': 56, 'pres': 57, 'pssv': 58, 'sing': 59, 'tran': 60, 'voct': 61}, 'ID_TO_PUNCTUATION': {0: '$empty', 1: ',', 2: '.'}, 'INFECT_TYPE_TO_ID': {'nothing': 0, 'REPLACE_UNDEF': 1, 'INCORRECT_PUNCT_RANDOM_PLACE': 2, 'INCORRECT_PUNCT_CENTER': 3, 'CORRECT_PUNCT_CENTER': 4, 'CORRECT_PUNCT_RIGHT': 5}, 'ID_TO_INFECT_TYPE': {0: 'nothing', 1: 'REPLACE_UNDEF', 2: 'INCORRECT_PUNCT_RANDOM_PLACE', 3: 'INCORRECT_PUNCT_CENTER', 4: 'CORRECT_PUNCT_CENTER', 5: 'CORRECT_PUNCT_RIGHT'}, 'VARIANT_FEATURES_CNT': 63, 'EMBEDDING_FEATURES_CNT': 300, 'TOTAL_WORD_FEATURES_CNT': 489, 'VARIANT_PROB_IDX': 62, 'INPUT_WORDS_CNT_RIGHT': 16, 'INPUT_WORDS_CNT_LEFT': 16, 'train_test_split': 0.9, 'chunk_size': 10, 'batch_size': 20000, 'max_parallel': 3, 'max_last_read_queue_size': 1}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pymorphy3\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import dill\n",
    "from razdel import tokenize\n",
    "\n",
    "from dataset_builder import calculate_word_features_for_tokens, PAD_TOKEN,get_word_features\n",
    "from inference import torch_model_runner, onnx_model_runner, infer\n",
    "from storage import Storage\n",
    "\n",
    "prefix = \"results_big_model_GOOD_2022-05-15\"\n",
    "onnx_model = onnx_model_runner(f\"{prefix}/model.onnx\")\n",
    "# with open(f\"{prefix}/storage_path.dill\", \"rb\") as f:\n",
    "#     storage_path = dill.load(f)\n",
    "# storage = Storage(storage_path, enable_watcher=False)\n",
    "# params = storage.get_meta('params')\n",
    "with open(f\"params2.dill\", \"rb\") as f:\n",
    "    params = dill.load(f)\n",
    "print(params)\n",
    "\n",
    "\n",
    "class jsinfer:\n",
    "    async def infer(arr):\n",
    "        class wrapper:\n",
    "            def to_py():\n",
    "                return onnx_model(arr)\n",
    "        return wrapper\n",
    "\n",
    "from stream import Stream\n",
    "import functools\n",
    "from collections import deque\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "@functools.lru_cache(maxsize=128)\n",
    "def get_word_features_cached(word):\n",
    "    return get_word_features(word, params).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я кое-как резолвлю, но не уверен, что итоговый результат заработае??'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Substr:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Substring(-1, -1, {self.text})\"\n",
    "\n",
    "def d_as_str(d):\n",
    "  return \"<\" + \" \".join(map(lambda text: text.text, d))+ \">\"\n",
    "\n",
    "async def infer_optimal(params, text):\n",
    "  # print(\"INFERCENC IS WIERD\\n\" * 10)\n",
    "  res = []\n",
    "  last_inserted_pos = 0\n",
    "  def sink(token, log=False):\n",
    "    nonlocal last_inserted_pos\n",
    "    if token.text == \"PAD\": return\n",
    "    if log: print('sink', token)\n",
    "    if isinstance(token, Substr):\n",
    "      res.append(token.text)\n",
    "      if log: print(\"added1 \", f\"`{token.text}`\", token)\n",
    "    else:\n",
    "      if last_inserted_pos != token.start:\n",
    "        res.append(text[last_inserted_pos: token.start])\n",
    "        if log: print(\"added2 \", f\"`{text[last_inserted_pos: token.start]}`\", last_inserted_pos, token.start)\n",
    "      last_inserted_pos = token.stop\n",
    "      res.append(token.text)\n",
    "      if log: print(\"added3 \", f\"`{token.text}`\", token)\n",
    "\n",
    "  def skip(token, log=False):\n",
    "    nonlocal last_inserted_pos\n",
    "    last_inserted_pos = token.stop\n",
    "    if log: print('skip', token)\n",
    "\n",
    "  def sink_remaining():\n",
    "     res.append(text[last_inserted_pos:])\n",
    "\n",
    "\n",
    "  async def predict_on_tokens(window_left, window_right, return_probas):\n",
    "    features = [get_word_features_cached(i.text) for i in Stream(window_left).chain(window_right)]\n",
    "    features_for_batch = np.stack((features, ))\n",
    "    arr = np.ascontiguousarray(features_for_batch, dtype=np.float32)\n",
    "    output_probas = np.array((await jsinfer.infer(arr)).to_py())\n",
    "    # output_probas[0][0] += 2.\n",
    "    if return_probas:\n",
    "      return params[\"ID_TO_PUNCTUATION\"], output_probas\n",
    "    punct_idx = np.argmax(output_probas).item()\n",
    "    punct = params[\"ID_TO_PUNCTUATION\"][punct_idx]\n",
    "    return punct\n",
    "\n",
    "\n",
    "  window_left = deque()\n",
    "  window_right = deque()\n",
    "  log = False\n",
    "  skip_next = False\n",
    "  for i in Stream.repeat(Substr(PAD_TOKEN), params['INPUT_WORDS_CNT_LEFT']) \\\n",
    "      .chain(Stream(tokenize(text))) \\\n",
    "      .chain(Stream.repeat(Substr(PAD_TOKEN), params[\"INPUT_WORDS_CNT_RIGHT\"])):\n",
    "    window_right.append(i)\n",
    "    if len(window_right) <= params[\"INPUT_WORDS_CNT_RIGHT\"]:\n",
    "        continue\n",
    "    assert len(window_right) == params[\"INPUT_WORDS_CNT_RIGHT\"] + 1\n",
    "\n",
    "    next_ = window_right.popleft()\n",
    "    sink(next_)\n",
    "    window_left.append(next_)\n",
    "    if len(window_left) < params['INPUT_WORDS_CNT_LEFT']:\n",
    "      continue\n",
    "\n",
    "    assert len(window_left) == params[\"INPUT_WORDS_CNT_LEFT\"]\n",
    "    assert len(window_right) == params[\"INPUT_WORDS_CNT_RIGHT\"]\n",
    "\n",
    "    if skip_next or window_right[0].text in '?!':\n",
    "      prediction = \"$skip\"\n",
    "    else:\n",
    "      # params[\"ID_TO_PUNCTUATION\"], output_probas\n",
    "      prediction = await predict_on_tokens(window_left, window_right, return_probas=False)\n",
    "\n",
    "\n",
    "    #random.choice([\" \", \".\"])\n",
    "    if log: print(d_as_str(window_left).rjust(100), prediction.center(6), d_as_str(window_right))\n",
    "\n",
    "    def is_replaceable_punct(punct):\n",
    "      return punct in ',.'\n",
    "\n",
    "    if prediction == \"$skip\":\n",
    "      pass\n",
    "    elif prediction != \"$empty\":\n",
    "      if is_replaceable_punct(window_right[0].text):\n",
    "        if window_right[0].text != prediction:\n",
    "          window_right[0].text = prediction\n",
    "      else:\n",
    "        window_left.append(Substr(prediction))\n",
    "        sink(window_left[-1])\n",
    "    else:\n",
    "      if is_replaceable_punct(window_right[0].text):\n",
    "          skip(window_right.popleft())\n",
    "\n",
    "    skip_next = is_replaceable_punct(window_right[0].text) or window_right[0].text in '?!'\n",
    "\n",
    "    while len(window_left) != params['INPUT_WORDS_CNT_LEFT'] - 1:\n",
    "      token = window_left.popleft()\n",
    "\n",
    "    if log: print(d_as_str(window_left).rjust(100), \"      \", d_as_str(window_right))\n",
    "\n",
    "  for i in window_right:\n",
    "    sink(i)\n",
    "  sink_remaining()\n",
    "  ress = \"\".join(res)\n",
    "  return ress\n",
    "\n",
    "await infer_optimal(params, \"я кое-как резолвлю но не уверен что итоговый результат заработае??\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
